{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d6396a7",
   "metadata": {},
   "source": [
    "# Multi-Taxi Environment Demonstration\n",
    "## In the followin example we will demonstrate:\n",
    "1. Setting up the environment.\n",
    "2. The different formats of observations.\n",
    "3. Doc the adjustable parameters.\n",
    "4. Show how to change the reward table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2003c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/\n",
      "Collecting MultiTaxiLib==0.1.2\n",
      "  Downloading https://test-files.pythonhosted.org/packages/c0/30/7300df09633222c4a6988d3a4bbc12cedb86c6120e5d95bf6ff3dbb96c34/MultiTaxiLib-0.1.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: gym in /home/ofir/anaconda3/envs/test_libs/lib/python3.8/site-packages (from MultiTaxiLib==0.1.2) (0.22.0)\n",
      "Requirement already satisfied: numpy in /home/ofir/anaconda3/envs/test_libs/lib/python3.8/site-packages (from MultiTaxiLib==0.1.2) (1.22.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/ofir/anaconda3/envs/test_libs/lib/python3.8/site-packages (from gym->MultiTaxiLib==0.1.2) (2.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/ofir/anaconda3/envs/test_libs/lib/python3.8/site-packages (from gym->MultiTaxiLib==0.1.2) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0; python_version < \"3.10\" in /home/ofir/anaconda3/envs/test_libs/lib/python3.8/site-packages (from gym->MultiTaxiLib==0.1.2) (4.11.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ofir/anaconda3/envs/test_libs/lib/python3.8/site-packages (from importlib-metadata>=4.10.0; python_version < \"3.10\"->gym->MultiTaxiLib==0.1.2) (3.7.0)\n",
      "Installing collected packages: MultiTaxiLib\n",
      "  Attempting uninstall: MultiTaxiLib\n",
      "    Found existing installation: MultiTaxiLib 0.1.1\n",
      "    Uninstalling MultiTaxiLib-0.1.1:\n",
      "      Successfully uninstalled MultiTaxiLib-0.1.1\n",
      "Successfully installed MultiTaxiLib-0.1.2\n"
     ]
    }
   ],
   "source": [
    "# installing easily via pip\n",
    "!pip install -i https://test.pypi.org/simple/ MultiTaxiLib==0.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a1c70a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/ofir/anaconda3/envs/test_libs/lib/python3.8/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 8.1.2. Several security issues (CVE-2021-27921, CVE-2021-25290, CVE-2021-25291, CVE-2021-25293, and more) have been fixed in pillow 8.1.2 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "from MultiTaxiLib.taxi_environment import TaxiEnv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dafd282",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_instance = TaxiEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2786ed22",
   "metadata": {},
   "source": [
    "### Observations\n",
    "The observations returned as a dictionary with the keys being \"taxi_{i}\", such that each item is the observation of agent \"i\", starting with i=1.\n",
    "\n",
    "An observation could be either an image, which is a window of sight for the agent, or a sybolic vector consists of: <code>[\n",
    "            taxi_row, taxi_col, taxi_fuel, \n",
    "            passenger1_row, passenger1_col... passenger_n_row, passenger_n_col,\n",
    "            passenger1_dest_row, passenger1_dest_col... passenger_n_dest_row, passenger_n_dest_col,\n",
    "            passenger1_status... passenger_n_status\n",
    "        ]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57efb548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbolic Vector Observation no others:\n",
      "[4 4 0 4 0 0 0 2]\n",
      "Symbolic Vector Observation with others:\n",
      "[4 0 0 0 0 0 4 4 4 2]\n",
      "Image Observation:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efc87e974c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_instance_image_obs = TaxiEnv(observation_type='image')\n",
    "env_instance_symbolic_obs_no_others = TaxiEnv(num_taxis=2, observation_type='symbolic', can_see_others=False)\n",
    "env_instance_symbolic_obs_with_others = TaxiEnv(num_taxis=2, observation_type='symbolic', can_see_others=True)\n",
    "\n",
    "print(f\"Symbolic Vector Observation no others:\\n{env_instance_symbolic_obs_no_others.reset()['taxi_1']}\")\n",
    "print(f\"Symbolic Vector Observation with others:\\n{env_instance_symbolic_obs_with_others.reset()['taxi_1']}\")\n",
    "print(\"Image Observation:\")\n",
    "plt.imshow(env_instance_image_obs.reset()['taxi_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498cafa",
   "metadata": {},
   "source": [
    "__Note:__ In image observations, fuel and gas station will have distinct colors (pink and purple), and passengers current locations and destinations will have close colors by values.\n",
    "\n",
    "__Also, note:__ In symbolic observations, we can choose wether taxis are aware of each other via the hyper parameter <code>can_see_others</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5dfbc1",
   "metadata": {},
   "source": [
    "### Environment's Parameters\n",
    "1. <code>num_taxis</code> - the number of taxis operating in the envorinment. _default=1_.\n",
    "2. <code>num_passengers</code> - the number of passengers to drive in the envorinment. _default=1_.\n",
    "3. <code>max_fuel</code> - if <code>None</code> - each taxi has unlimited fuel to spent, else, this is the amount of fuel in a full-tank, and this amount decreases by 1 in each timestep unless taxis fill their tank at the station with a special action._default=<code>None</code>_.\n",
    "4. <code>domain_map</code> - array of chars, representing the environment map with special characters for taxis initilized spots and fuel stations. _default=pre-defined map_.\n",
    "5. <code>taxis_capacity</code> - a list of integers, where the i'th element represents the i'th taxi's passengers limit, where <code>None</code> represents unlimitted capacity. _default=None_.\n",
    "6. <code>collision_sensitive_domain</code> - if <code>True</code> - taxis that move to the same grid point in the map - collide and stop their operation, otherwise, there can be multiple taxis at the same grid point. _default=False_.\n",
    "7. <code>fuel_type_list</code> - a list of either 'F' or 'G', where each element represents the fuel type of each taxi (F for *F*uel and G for *G*as), if <code>None</code> - all are fuel. _default=None_.\n",
    "8. <code>option_to_stand_by</code> - if <code>True</code> - taxis have the option to take *no_action*. _default=False_.\n",
    "9. <code>view_len</code> - relevant for image observations, defines the size of the window of sight of the taxis' observations, _default=2_.\n",
    "10. <code>rewards_table</code> - a dictionary that defines changes in the original reward table, see description below, _default=default_reward_table_.\n",
    "11. <code>observation_type</code> - either 'symbolic' or 'image', indicating the type of observations to the taxis, _default='symbolic'.\n",
    "12. <code>can_see_others</code> - If <code>True</code> and in symbolic observations mode, taxis will have other taxis' locations in their observations. _default=<code>False</code>,_. Note that in image oservations taxis can always see each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0091029f",
   "metadata": {},
   "source": [
    "### Changing the Reward Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a8fee8",
   "metadata": {},
   "source": [
    "The default reward table is:\n",
    "<code>\n",
    "    dict(\n",
    "    step=-1,\n",
    "    no_fuel=-1,\n",
    "    bad_pickup=-1,\n",
    "    bad_dropoff=-1,\n",
    "    bad_refuel=-1,\n",
    "    bad_fuel=-1,\n",
    "    pickup=-1,\n",
    "    standby_engine_off=-1,\n",
    "    turn_engine_on=-1,\n",
    "    turn_engine_off=-1,\n",
    "    standby_engine_on=-1,\n",
    "    intermediate_dropoff=2,\n",
    "    final_dropoff=100,\n",
    "    hit_wall=-1,\n",
    "    collision=-1,\n",
    "    collided=-1,\n",
    "    unrelated_action=-1,\n",
    ")</code>\n",
    "\n",
    "Note that it is intended to be very elaborate. In the default version, the taxis get <code>-1</code> for default actions and \"time that goes by\", and this apply for many scenarios, s.t bad_pickup, standby, step...\n",
    "\n",
    "We can use this elaboration in our advantage for customizing this dictionary (or only the parts of it that we would like to change, and then initialize an environment with our reward table of interest.\n",
    "\n",
    "#### In the next example we'll initialize an environment where we speciall penalize taxis for making <code>bad_pickup</code> tries, all other rewards are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f2679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customized_reward = dict(bad_pickup=-50)\n",
    "env_instance_image_obs = TaxiEnv(rewards_table=customized_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a7dbb",
   "metadata": {},
   "source": [
    "### For your convenience, we are also adding a simple example on training RLLib agents (PPO in this case) in our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f44bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-25 00:04:59 (running for 00:00:26.69)<br>Memory usage on this node: 6.5/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/8 CPUs, 0/0 GPUs, 0.0/1.8 GiB heap, 0.0/0.9 GiB objects<br>Result logdir: /home/ofir/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.examples.models.shared_weights_model import TorchSharedWeightsModel\n",
    "\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "# Register the models to use.\n",
    "mod1 = mod2 = TorchSharedWeightsModel\n",
    "ModelCatalog.register_custom_model(\"model1\", mod1)\n",
    "ModelCatalog.register_custom_model(\"model2\", mod2)\n",
    "\n",
    "num_policies = 2\n",
    "num_agents = 2\n",
    "\n",
    "# Each policy can have a different configuration (including custom model).\n",
    "def gen_policy(i):\n",
    "    config = {\n",
    "        \"model\": {\n",
    "            \"custom_model\": [\"model1\", \"model2\"][i % 2],\n",
    "        },\n",
    "        \"gamma\": random.choice([0.95, 0.99]),\n",
    "    }\n",
    "    return PolicySpec(config=config)\n",
    "\n",
    "# Setup PPO with an ensemble of `num_policies` different policies.\n",
    "policies = {\"taxi_{}\".format(i+1): gen_policy(i) for i in range(num_policies)}\n",
    "policy_ids = list(policies.keys())\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    pol_id = random.choice(policy_ids)\n",
    "    return pol_id\n",
    "\n",
    "config = {\n",
    "    \"env\": TaxiEnv,\n",
    "    \"env_config\": {\n",
    "        \"taxis_number\": num_agents,\n",
    "        \"can_see_others\": True\n",
    "    },\n",
    "    \"num_sgd_iter\": 100,\n",
    "    \"multiagent\": {\n",
    "        \"policies\": policies,\n",
    "        \"policy_mapping_fn\": policy_mapping_fn,\n",
    "    },\n",
    "    \"framework\": \"torch\",\n",
    "}\n",
    "stop = {\n",
    "    \"episode_reward_mean\": 150,\n",
    "    \"timesteps_total\": 100000,\n",
    "    \"training_iteration\": 10000,\n",
    "}\n",
    "\n",
    "results = tune.run(\"PPO\", stop=stop, config=config, verbose=1)\n",
    "check_learning_achieved(results, 150)\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "010ad802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'taxi_1': array([0, 0, 0, 4, 4, 0, 4, 2])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = TaxiEnv()\n",
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade16ea0",
   "metadata": {},
   "source": [
    "### And just like that! We are good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a0455",
   "metadata": {},
   "source": [
    "### After initializing the environemnt you can deploy to it any planner/ RL/ MARL algorithms that you like and works with gym.\n",
    "\n",
    "# Enjoy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}